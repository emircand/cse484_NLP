{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c4e17cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pywrapfst as fst\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89b594d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plural_fst():\n",
    "    front_vowels = ['e', 'i', 'ö', 'ü']\n",
    "    back_vowels = ['a', 'ı', 'o', 'u']\n",
    "    consonants = \"bcçdfgğhjklmnprsştvyz\"  # Add more if needed\n",
    "\n",
    "    sym_table = fst.SymbolTable()\n",
    "    sym_table.add_symbol('<eps>', 0)\n",
    "    for char in front_vowels + back_vowels + list(consonants) + ['ler', 'lar', '+PL']:\n",
    "        sym_table.add_symbol(char)\n",
    "\n",
    "    plural_fst = fst.Fst()\n",
    "    plural_fst.set_input_symbols(sym_table)\n",
    "    plural_fst.set_output_symbols(sym_table)\n",
    "\n",
    "    one = fst.Weight('tropical', 1.0)\n",
    "\n",
    "    start_state = plural_fst.add_state()\n",
    "    front_state = plural_fst.add_state()\n",
    "    back_state = plural_fst.add_state()\n",
    "    end_state = plural_fst.add_state()\n",
    "\n",
    "    plural_fst.set_start(start_state)\n",
    "    plural_fst.set_final(end_state)\n",
    "\n",
    "    for vowel in front_vowels:\n",
    "        plural_fst.add_arc(start_state, fst.Arc(sym_table.find(vowel), sym_table.find(vowel), one, front_state))\n",
    "        plural_fst.add_arc(back_state, fst.Arc(sym_table.find(vowel), sym_table.find(vowel), one, front_state))\n",
    "        plural_fst.add_arc(front_state, fst.Arc(sym_table.find(vowel), sym_table.find(vowel), one, front_state))\n",
    "    for vowel in back_vowels:\n",
    "        plural_fst.add_arc(start_state, fst.Arc(sym_table.find(vowel), sym_table.find(vowel), one, back_state))\n",
    "        plural_fst.add_arc(front_state, fst.Arc(sym_table.find(vowel), sym_table.find(vowel), one, back_state))\n",
    "        plural_fst.add_arc(back_state, fst.Arc(sym_table.find(vowel), sym_table.find(vowel), one, back_state))\n",
    "\n",
    "    plural_fst.add_arc(front_state, fst.Arc(sym_table.find('+PL'), sym_table.find('ler'), one, end_state))\n",
    "    plural_fst.add_arc(back_state, fst.Arc(sym_table.find('+PL'), sym_table.find('lar'), one, end_state))\n",
    "\n",
    "    # Looping back for consonants and non-vowel characters\n",
    "    for consonant in consonants:\n",
    "        consonant_id = sym_table.find(consonant)\n",
    "        plural_fst.add_arc(start_state, fst.Arc(consonant_id, consonant_id, one, start_state))\n",
    "        plural_fst.add_arc(front_state, fst.Arc(consonant_id, consonant_id, one, front_state))\n",
    "        plural_fst.add_arc(back_state, fst.Arc(consonant_id, consonant_id, one, back_state))\n",
    "    \n",
    "    return plural_fst\n",
    "\n",
    "# Create and test the FST\n",
    "plural_fst = create_plural_fst()\n",
    "plural_fst.write('plural.fst')\n",
    "!fstdraw plural.fst | dot -Tpng > plural.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cadef763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transduce_sequence_det(f, seq):\n",
    "    eps = f.input_symbols().find('<eps>')\n",
    "    curr_state = f.start()\n",
    "    output = []\n",
    "\n",
    "    for char in seq:\n",
    "        label = f.input_symbols().find(char)\n",
    "        if label == -1:\n",
    "            print(f\"Character '{char}' not found in FST's input symbols.\")\n",
    "            return []\n",
    "\n",
    "        found = False\n",
    "        for arc in f.arcs(curr_state):\n",
    "            if arc.ilabel == label:\n",
    "                output.append(arc.olabel)\n",
    "                curr_state = arc.nextstate\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        if not found:\n",
    "            print(f\"No transition for '{char}' in current state.\")\n",
    "            return []\n",
    "\n",
    "    final_weight = float(f.final(curr_state))\n",
    "    if final_weight != math.inf:  # if this is a final state\n",
    "        out_seq = [f.output_symbols().find(w) for w in output]\n",
    "        return out_seq\n",
    "    else:\n",
    "        print(\"Reached a non-final state at the end of the sequence.\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30c07eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def pluralize_word(word, plural_fst):\n",
    "    char_sequence = list(word)\n",
    "    char_sequence = char_sequence + ['+PL']\n",
    "    transduced_sequence = transduce_sequence_det(plural_fst, char_sequence)\n",
    "\n",
    "    # Decode each byte string in the sequence to a regular string\n",
    "    decoded_sequence = [symbol.decode('utf-8') if isinstance(symbol, bytes) else symbol for symbol in transduced_sequence]\n",
    "\n",
    "    # Join the sequence to form the pluralized word\n",
    "    pluralized_word = ''.join(decoded_sequence)\n",
    "    return pluralized_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbcc8216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def possessive_fst():\n",
    "    _table = fst.SymbolTable()\n",
    "    _fst = fst.Fst()\n",
    "    \n",
    "    def create_symbol_table():\n",
    "        # Define the list of symbols\n",
    "        symbols = ['+1ps', 'm', 'im', '+2ps', 'n', 'in', '+3ps', 'si', \n",
    "                'i', '+1pm', 'miz', 'imiz', '+2pm', 'niz', 'iniz', \n",
    "                '+3pm', 'leri','üm', 'ün', 'sü', 'ü', 'müz', 'ümüz', \n",
    "                'nüz', 'ünüz', 'ları',\n",
    "                'ım', 'ın', 'sı', 'ı', 'mız', 'ımız', 'nız', 'ınız',\n",
    "                'um', 'un', 'su', 'u', 'umuz', 'unuz']\n",
    "\n",
    "        # Create the symbol table\n",
    "        table = fst.SymbolTable()\n",
    "\n",
    "        # Add the symbols to the symbol table\n",
    "        for symbol in symbols:\n",
    "            table.add_symbol(symbol)\n",
    "\n",
    "        return table\n",
    "\n",
    "# Use the function to create the symbol table\n",
    "    _table = create_symbol_table()\n",
    "    \n",
    "    front_vowels_ei = ['e', 'i']\n",
    "    front_vowels_ou = ['ö', 'ü']\n",
    "    back_vowels_ai = ['a', 'ı']\n",
    "    back_vowels_ou = ['o', 'u']\n",
    "\n",
    "    front_vowels = front_vowels_ei + front_vowels_ou\n",
    "    back_vowels = back_vowels_ai + back_vowels_ou\n",
    "    consonants = \"bcçdfgğhjklmnprsştvyz\"  # Add more if needed\n",
    "    \n",
    "    for char in front_vowels + back_vowels + list(consonants):\n",
    "        _table.add_symbol(char)\n",
    "        \n",
    "    _fst.set_input_symbols(_table)\n",
    "    _fst.set_output_symbols(_table)\n",
    "\n",
    "    one = None\n",
    "    \n",
    "    start_state = _fst.add_state()\n",
    "\n",
    "    bw_ou_c_state = _fst.add_state()\n",
    "    bw_ai_c_state = _fst.add_state()\n",
    "    fw_ei_c_state = _fst.add_state()\n",
    "    fw_ou_c_state = _fst.add_state()\n",
    "    \n",
    "    fw_ou_state = _fst.add_state()\n",
    "    fw_ei_state = _fst.add_state()\n",
    "    bw_ai_state = _fst.add_state()\n",
    "    bw_ou_state = _fst.add_state()\n",
    "\n",
    "    end_state = _fst.add_state()\n",
    "    \n",
    "    _fst.set_start(start_state)\n",
    "    _fst.set_final(end_state)\n",
    "\n",
    "    for vowel in front_vowels_ei:\n",
    "        _fst.add_arc(start_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, fw_ei_state))\n",
    "        _fst.add_arc(bw_ou_c_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, fw_ei_state))\n",
    "        _fst.add_arc(bw_ai_c_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, fw_ei_state))\n",
    "        _fst.add_arc(fw_ei_c_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, fw_ei_state))\n",
    "        _fst.add_arc(fw_ou_c_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, fw_ei_state))\n",
    "        _fst.add_arc(fw_ou_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, fw_ei_state))\n",
    "        _fst.add_arc(fw_ei_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, fw_ei_state))\n",
    "\n",
    "    for vowel in front_vowels_ou:\n",
    "        _fst.add_arc(start_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, fw_ou_state))\n",
    "        _fst.add_arc(bw_ou_c_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, fw_ou_state))\n",
    "        _fst.add_arc(bw_ai_c_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, fw_ou_state))\n",
    "        _fst.add_arc(fw_ei_c_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, fw_ou_state))\n",
    "        _fst.add_arc(fw_ou_c_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, fw_ou_state))\n",
    "        _fst.add_arc(fw_ou_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, fw_ou_state))\n",
    "        _fst.add_arc(fw_ei_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, fw_ou_state))\n",
    "\n",
    "    for vowel in back_vowels_ai:\n",
    "        _fst.add_arc(start_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, bw_ai_state))\n",
    "        _fst.add_arc(bw_ou_c_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, bw_ai_state))\n",
    "        _fst.add_arc(bw_ai_c_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, bw_ai_state))\n",
    "        _fst.add_arc(fw_ei_c_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, bw_ai_state))\n",
    "        _fst.add_arc(fw_ou_c_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, bw_ai_state))\n",
    "        _fst.add_arc(bw_ai_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, bw_ai_state))\n",
    "        _fst.add_arc(bw_ou_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, bw_ai_state))\n",
    "\n",
    "    for vowel in back_vowels_ou:\n",
    "        _fst.add_arc(start_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, bw_ou_state))\n",
    "        _fst.add_arc(bw_ou_c_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, bw_ou_state))\n",
    "        _fst.add_arc(bw_ai_c_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, bw_ou_state))\n",
    "        _fst.add_arc(fw_ei_c_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, bw_ou_state))\n",
    "        _fst.add_arc(fw_ou_c_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, bw_ou_state))\n",
    "        _fst.add_arc(bw_ai_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, bw_ou_state))\n",
    "        _fst.add_arc(bw_ou_state, fst.Arc(_table.find(vowel), _table.find(vowel), one, bw_ou_state))\n",
    "\n",
    "    #plural_fst.add_arc(back_state, fst.Arc(sym_table.find(vowel), sym_table.find(vowel), one, front_state))\n",
    "    \n",
    "    _fst.add_arc(fw_ei_state, fst.Arc(_table.find('+1ps'),_table.find('m'), one, end_state))\n",
    "    _fst.add_arc(fw_ei_c_state, fst.Arc(_table.find('+1ps'),_table.find('im'), one, end_state))\n",
    "    _fst.add_arc(fw_ei_state, fst.Arc(_table.find('+2ps'),_table.find('n'), one, end_state))\n",
    "    _fst.add_arc(fw_ei_c_state, fst.Arc(_table.find('+2ps'),_table.find('in'), one, end_state))\n",
    "    _fst.add_arc(fw_ei_state, fst.Arc(_table.find('+3ps'),_table.find('si'), one, end_state))\n",
    "    _fst.add_arc(fw_ei_c_state, fst.Arc(_table.find('+3ps'),_table.find('i'), one, end_state))\n",
    "    _fst.add_arc(fw_ei_state, fst.Arc(_table.find('+1pm'),_table.find('miz'), one, end_state))\n",
    "    _fst.add_arc(fw_ei_c_state, fst.Arc(_table.find('+1pm'),_table.find('imiz'), one, end_state))\n",
    "    _fst.add_arc(fw_ei_state, fst.Arc(_table.find('+2pm'),_table.find('niz'), one, end_state))\n",
    "    _fst.add_arc(fw_ei_c_state, fst.Arc(_table.find('+2pm'),_table.find('iniz'), one, end_state))\n",
    "    _fst.add_arc(fw_ei_state, fst.Arc(_table.find('+3pm'),_table.find('leri'), one, end_state))\n",
    "    _fst.add_arc(fw_ei_c_state, fst.Arc(_table.find('+3pm'),_table.find('leri'), one, end_state))\n",
    "\n",
    "    _fst.add_arc(fw_ou_state, fst.Arc(_table.find('+1ps'),_table.find('m'), one, end_state))\n",
    "    _fst.add_arc(fw_ou_c_state, fst.Arc(_table.find('+1ps'),_table.find('üm'), one, end_state))\n",
    "    _fst.add_arc(fw_ou_state, fst.Arc(_table.find('+2ps'),_table.find('n'), one, end_state))\n",
    "    _fst.add_arc(fw_ou_c_state, fst.Arc(_table.find('+2ps'),_table.find('ün'), one, end_state))\n",
    "    _fst.add_arc(fw_ou_state, fst.Arc(_table.find('+3ps'),_table.find('sü'), one, end_state))\n",
    "    _fst.add_arc(fw_ou_c_state, fst.Arc(_table.find('+3ps'),_table.find('ü'), one, end_state))\n",
    "    _fst.add_arc(fw_ou_state, fst.Arc(_table.find('+1pm'),_table.find('müz'), one, end_state))\n",
    "    _fst.add_arc(fw_ou_c_state, fst.Arc(_table.find('+1pm'),_table.find('ümüz'), one, end_state))\n",
    "    _fst.add_arc(fw_ou_state, fst.Arc(_table.find('+2pm'),_table.find('nüz'), one, end_state))\n",
    "    _fst.add_arc(fw_ou_c_state, fst.Arc(_table.find('+2pm'),_table.find('ünüz'), one, end_state))\n",
    "    _fst.add_arc(fw_ou_state, fst.Arc(_table.find('+3pm'),_table.find('leri'), one, end_state))\n",
    "    _fst.add_arc(fw_ou_c_state, fst.Arc(_table.find('+3pm'),_table.find('leri'), one, end_state))\n",
    "\n",
    "    _fst.add_arc(bw_ai_state, fst.Arc(_table.find('+1ps'),_table.find('m'), one, end_state))\n",
    "    _fst.add_arc(bw_ai_c_state, fst.Arc(_table.find('+1ps'),_table.find('ım'), one, end_state))\n",
    "    _fst.add_arc(bw_ai_state, fst.Arc(_table.find('+2ps'),_table.find('n'), one, end_state))\n",
    "    _fst.add_arc(bw_ai_c_state, fst.Arc(_table.find('+2ps'),_table.find('ın'), one, end_state))\n",
    "    _fst.add_arc(bw_ai_state, fst.Arc(_table.find('+3ps'),_table.find('sı'), one, end_state))\n",
    "    _fst.add_arc(bw_ai_c_state, fst.Arc(_table.find('+3ps'),_table.find('ı'), one, end_state))\n",
    "    _fst.add_arc(bw_ai_state, fst.Arc(_table.find('+1pm'),_table.find('mız'), one, end_state))\n",
    "    _fst.add_arc(bw_ai_c_state, fst.Arc(_table.find('+1pm'),_table.find('ımız'), one, end_state))\n",
    "    _fst.add_arc(bw_ai_state, fst.Arc(_table.find('+2pm'),_table.find('nız'), one, end_state))\n",
    "    _fst.add_arc(bw_ai_c_state, fst.Arc(_table.find('+2pm'),_table.find('ınız'), one, end_state))\n",
    "    _fst.add_arc(bw_ai_state, fst.Arc(_table.find('+3pm'),_table.find('ları'), one, end_state))\n",
    "    _fst.add_arc(bw_ai_c_state, fst.Arc(_table.find('+3pm'),_table.find('ları'), one, end_state))\n",
    "\n",
    "    _fst.add_arc(bw_ou_state, fst.Arc(_table.find('+1ps'),_table.find('m'), one, end_state))\n",
    "    _fst.add_arc(bw_ou_c_state, fst.Arc(_table.find('+1ps'),_table.find('um'), one, end_state))\n",
    "    _fst.add_arc(bw_ou_state, fst.Arc(_table.find('+2ps'),_table.find('n'), one, end_state))\n",
    "    _fst.add_arc(bw_ou_c_state, fst.Arc(_table.find('+2ps'),_table.find('un'), one, end_state))\n",
    "    _fst.add_arc(bw_ou_state, fst.Arc(_table.find('+3ps'),_table.find('su'), one, end_state))\n",
    "    _fst.add_arc(bw_ou_c_state, fst.Arc(_table.find('+3ps'),_table.find('u'), one, end_state))\n",
    "    _fst.add_arc(bw_ou_state, fst.Arc(_table.find('+1pm'),_table.find('mız'), one, end_state))\n",
    "    _fst.add_arc(bw_ou_c_state, fst.Arc(_table.find('+1pm'),_table.find('umuz'), one, end_state))\n",
    "    _fst.add_arc(bw_ou_state, fst.Arc(_table.find('+2pm'),_table.find('nız'), one, end_state))\n",
    "    _fst.add_arc(bw_ou_c_state, fst.Arc(_table.find('+2pm'),_table.find('unuz'), one, end_state))\n",
    "    _fst.add_arc(bw_ou_state, fst.Arc(_table.find('+3pm'),_table.find('ları'), one, end_state))\n",
    "    _fst.add_arc(bw_ou_c_state, fst.Arc(_table.find('+3pm'),_table.find('ları'), one, end_state))\n",
    "    \n",
    "    # Looping back for consonants and non-vowel characters\n",
    "    for consonant in consonants:\n",
    "        consonant_id = _table.find(consonant)\n",
    "        _fst.add_arc(start_state, fst.Arc(consonant_id, consonant_id, one, start_state))\n",
    "        _fst.add_arc(bw_ai_state, fst.Arc(consonant_id, consonant_id, one, bw_ai_c_state))\n",
    "        _fst.add_arc(bw_ou_state, fst.Arc(consonant_id, consonant_id, one, bw_ou_c_state))\n",
    "        _fst.add_arc(fw_ei_state, fst.Arc(consonant_id, consonant_id, one, fw_ei_c_state))\n",
    "        _fst.add_arc(fw_ou_state, fst.Arc(consonant_id, consonant_id, one, fw_ou_c_state))\n",
    "        _fst.add_arc(bw_ai_c_state, fst.Arc(consonant_id, consonant_id, one, bw_ai_c_state))\n",
    "        _fst.add_arc(bw_ou_c_state, fst.Arc(consonant_id, consonant_id, one, bw_ou_c_state))\n",
    "        _fst.add_arc(fw_ei_c_state, fst.Arc(consonant_id, consonant_id, one, fw_ei_c_state))\n",
    "        _fst.add_arc(fw_ou_c_state, fst.Arc(consonant_id, consonant_id, one, fw_ou_c_state))\n",
    "    \n",
    "    \n",
    "    return _fst\n",
    "\n",
    "p_fst = possessive_fst()\n",
    "p_fst.write('possessive.fst')\n",
    "!fstdraw possessive.fst | dot -Tpng > possessive.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d85c7913",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def possessive_word(word, plural_fst, specifier):\n",
    "    char_sequence = list(word)\n",
    "    char_sequence = char_sequence + [specifier]\n",
    "    transduced_sequence = transduce_sequence_det(plural_fst, char_sequence)\n",
    "\n",
    "    # Decode each byte string in the sequence to a regular string\n",
    "    decoded_sequence = [symbol.decode('utf-8') if isinstance(symbol, bytes) else symbol for symbol in transduced_sequence]\n",
    "    # Join the sequence to form the pluralized word\n",
    "    pluralized_word = ''.join(decoded_sequence)\n",
    "    return pluralized_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b223e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: kulaklık, Specifier: +3ps -->  Expected: kulaklığı, Result: kulaklıkı\n",
      "2: kömür, Specifier: +2pm -->  Expected: kömürünüz, Result: kömürünüz\n",
      "3: ev, Specifier: +2ps -->  Expected: evin, Result: evin\n",
      "4: araba, Specifier: +1pm -->  Expected: arabamız, Result: arabamız\n",
      "5: kalem, Specifier: +2pm -->  Expected: kaleminiz, Result: kaleminiz\n",
      "6: çocuk, Specifier: +3pm -->  Expected: çocukları, Result: çocukları\n",
      "7: okul, Specifier: +1ps -->  Expected: okulum, Result: okulum\n",
      "8: pencere, Specifier: +2ps -->  Expected: penceren, Result: penceren\n",
      "9: kol, Specifier: +1pm -->  Expected: kolumuz, Result: kolumuz\n",
      "10: masa, Specifier: +2pm -->  Expected: masanız, Result: masanız\n",
      "11: kapı, Specifier: +3ps -->  Expected: kapısı, Result: kapısı\n"
     ]
    }
   ],
   "source": [
    "def test_possessive_suffix():\n",
    "    p_fst = possessive_fst()\n",
    "\n",
    "    # Define the test cases\n",
    "    test_cases = [\n",
    "        ('kulaklık', '+3ps', 'kulaklığı'),\n",
    "        ('kömür', '+2pm', 'kömürünüz'),\n",
    "        ('ev', '+2ps', 'evin'),\n",
    "        ('araba', '+1pm', 'arabamız'),\n",
    "        ('kalem', '+2pm', 'kaleminiz'),\n",
    "        ('çocuk', '+3pm', 'çocukları'),\n",
    "        ('okul', '+1ps', 'okulum'),\n",
    "        ('pencere', '+2ps', 'penceren'),\n",
    "        ('kol', '+1pm', 'kolumuz'),\n",
    "        ('masa', '+2pm', 'masanız'),\n",
    "        ('kapı', '+3ps', 'kapısı')\n",
    "    ]\n",
    "    i = 0\n",
    "    # Run the test cases\n",
    "    for word, specifier, expected in test_cases:\n",
    "        i=i+1\n",
    "        result = possessive_word(word, p_fst, specifier)\n",
    "        print(f'{i}: {word}, Specifier: {specifier} -->  Expected: {expected}, Result: {result}')\n",
    "\n",
    "test_possessive_suffix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "673e4260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: kulaklık -->  Expected: kulaklıklar, Result: kulaklıklar\n",
      "2: kitap -->  Expected: kitaplar, Result: kitaplar\n",
      "3: ev -->  Expected: evler, Result: evler\n",
      "4: araba -->  Expected: arabalar, Result: arabalar\n",
      "5: kalem -->  Expected: kalemler, Result: kalemler\n",
      "6: çocuk -->  Expected: çocuklar, Result: çocuklar\n",
      "7: okul -->  Expected: okullar, Result: okullar\n",
      "8: pencere -->  Expected: pencereler, Result: pencereler\n",
      "9: sandalye -->  Expected: sandalyeler, Result: sandalyeler\n",
      "10: masa -->  Expected: masalar, Result: masalar\n",
      "11: kapı -->  Expected: kapılar, Result: kapılar\n"
     ]
    }
   ],
   "source": [
    "def test_plural_suffix():\n",
    "    p_fst = create_plural_fst()\n",
    "\n",
    "    # Define the test cases\n",
    "    test_cases = [\n",
    "        ('kulaklık', 'kulaklıklar'),\n",
    "        ('kitap', 'kitaplar'),\n",
    "        ('ev', 'evler'),\n",
    "        ('araba', 'arabalar'),\n",
    "        ('kalem','kalemler'),\n",
    "        ('çocuk', 'çocuklar'),\n",
    "        ('okul', 'okullar'),\n",
    "        ('pencere', 'pencereler'),\n",
    "        ('sandalye', 'sandalyeler'),\n",
    "        ('masa', 'masalar'),\n",
    "        ('kapı', 'kapılar')\n",
    "    ]\n",
    "    i = 0\n",
    "    # Run the test cases\n",
    "    for word, expected in test_cases:\n",
    "        i=i+1\n",
    "        result = pluralize_word(word, p_fst)\n",
    "        print(f'{i}: {word} -->  Expected: {expected}, Result: {result}')\n",
    "\n",
    "test_plural_suffix()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
